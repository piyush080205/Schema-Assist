{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhLuisCp3RlpcqkSYxfcbd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyush080205/Schema-Assist/blob/main/SchemaAssist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8ofpbLQWCbxT"
      },
      "outputs": [],
      "source": [
        "!pip install -q duckdb cohere faiss-cpu plotly pandas gradio prophet kaleido\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cohere\n",
        "import faiss\n",
        "import duckdb\n",
        "import plotly.express as px\n",
        "from prophet import Prophet\n",
        "from prophet.plot import plot_plotly\n",
        "import gradio as gr\n",
        "import warnings\n",
        "import re\n",
        "from google.colab import userdata, files\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "COHERE_API_KEY = userdata.get('COHERE_API_KEY')\n",
        "co = cohere.ClientV2(api_key=COHERE_API_KEY)\n",
        "con = duckdb.connect(\":memory:\")\n",
        "\n",
        "print(\"‚úÖ Setup complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r2K9vCJKUPe",
        "outputId": "4ea69bb9-9163-48b8-c842-5892a621a3ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Setup complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üì§ Upload all 9 Olist CSV files now...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "table_mapping = {\n",
        "    \"olist_customers_dataset\": \"customers\",\n",
        "    \"olist_geolocation_dataset\": \"geolocation\",\n",
        "    \"olist_order_items_dataset\": \"order_items\",\n",
        "    \"olist_order_payments_dataset\": \"order_payments\",\n",
        "    \"olist_order_reviews_dataset\": \"order_reviews\",\n",
        "    \"olist_orders_dataset\": \"orders\",\n",
        "    \"olist_products_dataset\": \"products\",\n",
        "    \"olist_sellers_dataset\": \"sellers\",\n",
        "    \"product_category_name_translation\": \"category_translation\"\n",
        "}\n",
        "\n",
        "for uploaded_name in uploaded.keys():\n",
        "    base = uploaded_name.split(' (')[0].replace('.csv', '')\n",
        "    table_name = table_mapping.get(base, base.replace('olist_', '').replace('_dataset', ''))\n",
        "    try:\n",
        "        con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM read_csv_auto('{uploaded_name}', header=True)\")\n",
        "        print(f\"   ‚úÖ Loaded ‚Üí {table_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå {uploaded_name}: {e}\")\n",
        "\n",
        "print(\"\\nüéâ All tables loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "Lu3Cprr5Ksty",
        "outputId": "da01e93d-f947-4495-ce74-e341ff22a323"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Upload all 9 Olist CSV files now...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8db5bd05-a401-4690-a471-54f230007b56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8db5bd05-a401-4690-a471-54f230007b56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving olist_customers_dataset.csv to olist_customers_dataset (1).csv\n",
            "Saving olist_geolocation_dataset.csv to olist_geolocation_dataset (1).csv\n",
            "Saving olist_order_items_dataset.csv to olist_order_items_dataset (1).csv\n",
            "Saving olist_order_payments_dataset.csv to olist_order_payments_dataset (1).csv\n",
            "Saving olist_order_reviews_dataset.csv to olist_order_reviews_dataset (1).csv\n",
            "Saving olist_orders_dataset.csv to olist_orders_dataset (1).csv\n",
            "Saving olist_products_dataset.csv to olist_products_dataset (1).csv\n",
            "Saving olist_sellers_dataset.csv to olist_sellers_dataset (1).csv\n",
            "Saving product_category_name_translation.csv to product_category_name_translation (1).csv\n",
            "   ‚úÖ Loaded ‚Üí customers\n",
            "   ‚úÖ Loaded ‚Üí geolocation\n",
            "   ‚úÖ Loaded ‚Üí order_items\n",
            "   ‚úÖ Loaded ‚Üí order_payments\n",
            "   ‚úÖ Loaded ‚Üí order_reviews\n",
            "   ‚úÖ Loaded ‚Üí orders\n",
            "   ‚úÖ Loaded ‚Üí products\n",
            "   ‚úÖ Loaded ‚Üí sellers\n",
            "   ‚úÖ Loaded ‚Üí category_translation\n",
            "\n",
            "üéâ All tables loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_metadata(con):\n",
        "    tables = con.sql(\"SHOW TABLES\").df()['name'].tolist()\n",
        "    metadata = {}\n",
        "    for t in tables:\n",
        "        cols = con.sql(f\"DESCRIBE {t}\").df()[['column_name', 'column_type']].to_dict('records')\n",
        "        metadata[t] = {\"columns\": cols}\n",
        "    return metadata\n",
        "\n",
        "schema_metadata = extract_metadata(con)\n",
        "print(f\"‚úÖ {len(schema_metadata)} tables loaded\")\n",
        "\n",
        "documents = []\n",
        "for table_name, info in schema_metadata.items():\n",
        "    col_str = \"\\n\".join([f\"  - {c['column_name']} ({c['column_type']})\" for c in info[\"columns\"]])\n",
        "    doc = f\"Table: {table_name}\\nColumns:\\n{col_str}\\nUse category_translation for English names.\"\n",
        "    documents.append(doc)\n",
        "\n",
        "embed_response = co.embed(model=\"embed-v4.0\", texts=documents, input_type=\"search_document\", embedding_types=[\"float\"])\n",
        "embeddings = np.array(embed_response.embeddings.float).astype('float32')\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "print(\"‚úÖ FAISS ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZP9tQQUK0DW",
        "outputId": "7d733758-6362-42dc-dc57-ce7035834cda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted 9 tables\n",
            "‚úÖ FAISS ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql(user_query, schema_context, chat_history=None):\n",
        "    if chat_history is None: chat_history = []\n",
        "    system_prompt = \"\"\"You are an expert Olist analyst.\n",
        "Rules:\n",
        "- ALWAYS join with `category_translation` when showing product categories to show English names.\n",
        "- Return ONLY valid SELECT query with LIMIT 1000.\n",
        "- Use correct joins.\n",
        "- For revenue use payment_value.\n",
        "- Return ONLY the SQL.\"\"\"\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "    for turn in chat_history[-5:]:\n",
        "        messages.append({\"role\": \"user\", \"content\": turn[\"query\"]})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": turn[\"sql\"]})\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"Schema:\\n{schema_context}\\n\\nQuestion: {user_query}\"})\n",
        "\n",
        "    resp = co.chat(model=\"command-a-03-2025\", messages=messages, temperature=0.1)\n",
        "    sql = resp.message.content[0].text.strip()\n",
        "    if \"```\" in sql:\n",
        "        sql = sql.split(\"```\")[1].replace(\"sql\",\"\").strip()\n",
        "    return sql"
      ],
      "metadata": {
        "id": "qZ_2CtnaK4Jw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_query(sql):\n",
        "    sql_upper = sql.upper().strip()\n",
        "    if any(x in sql_upper for x in [\"DROP\",\"DELETE\",\"UPDATE\",\"INSERT\",\"CREATE\",\"ALTER\"]):\n",
        "        raise ValueError(\"Only SELECT allowed\")\n",
        "    return con.sql(sql).df()\n",
        "\n",
        "def explain_results(df, user_query, sql):\n",
        "    if df.empty:\n",
        "        return \"No data found.\", \"\"\n",
        "\n",
        "    table = re.search(r'FROM\\s+([a-z_]+)', sql, re.I)\n",
        "    table = table.group(1) if table else \"multiple\"\n",
        "    rows = len(df)\n",
        "\n",
        "    stats = [f\"**Rows:** {rows}\"]\n",
        "    num_cols = df.select_dtypes(include='number').columns.tolist()\n",
        "    if num_cols:\n",
        "        col = num_cols[0]\n",
        "        stats.extend([\n",
        "            f\"**Mean / Average:** {df[col].mean():,.2f}\",\n",
        "            f\"**Median:** {df[col].median():,.2f}\",\n",
        "            f\"**Mode:** {df[col].mode().iloc[0] if not df[col].mode().empty else 'N/A'}\"\n",
        "        ])\n",
        "\n",
        "    stats_text = \"\\n\".join(stats)\n",
        "    return f\"{stats_text}\\n\\nüí° Business Insight: Strong performance observed.\", stats_text"
      ],
      "metadata": {
        "id": "7h1MGrvSK5D0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_plot(df, user_query):\n",
        "    if df.empty:\n",
        "        return None\n",
        "\n",
        "    title = f\"üìà {user_query[:75]}\"\n",
        "    cols = df.columns.tolist()\n",
        "    num_cols = df.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "    # Year column handling\n",
        "    year_cols = [c for c in cols if any(x in c.lower() for x in ['year', 'purchase_year'])]\n",
        "    if year_cols and num_cols:\n",
        "        year_col = year_cols[0]\n",
        "        val_col = num_cols[0]\n",
        "        df_plot = df.copy()\n",
        "        df_plot[year_col] = df_plot[year_col].astype(str)\n",
        "        fig = px.bar(df_plot, x=year_col, y=val_col, title=title, text=val_col,\n",
        "                     color=year_col, color_discrete_sequence=px.colors.qualitative.Bold)\n",
        "        fig.update_traces(texttemplate='%{text:,.0f}', textposition='outside')\n",
        "        fig.update_layout(\n",
        "            height=620,\n",
        "            template=\"plotly_white\",\n",
        "            xaxis_title=\"Year\",\n",
        "            yaxis_title=val_col.replace(\"_\", \" \").title() + \" (BRL)\"\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    # Time series\n",
        "    date_cols = [c for c in cols if any(k in c.lower() for k in ['date','time','month'])]\n",
        "    if date_cols and num_cols:\n",
        "        df2 = df.copy()\n",
        "        df2[date_cols[0]] = pd.to_datetime(df2[date_cols[0]], errors='coerce')\n",
        "        df2['year'] = df2[date_cols[0]].dt.year.astype(str)\n",
        "        fig = px.line(df2, x=date_cols[0], y=num_cols[0], color='year',\n",
        "                      color_discrete_sequence=px.colors.qualitative.Bold,\n",
        "                      title=title, markers=True)\n",
        "        fig.update_layout(\n",
        "            height=620,\n",
        "            template=\"plotly_white\",\n",
        "            xaxis_title=\"Date\",\n",
        "            yaxis_title=num_cols[0].replace(\"_\", \" \").title()\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    # Fallback\n",
        "    if len(num_cols) >= 2:\n",
        "        fig = px.scatter(df, x=num_cols[0], y=num_cols[1], trendline=\"ols\", title=title)\n",
        "        fig.update_layout(xaxis_title=num_cols[0].replace(\"_\", \" \").title(),\n",
        "                          yaxis_title=num_cols[1].replace(\"_\", \" \").title())\n",
        "        return fig\n",
        "    elif num_cols:\n",
        "        return px.histogram(df, x=num_cols[0], title=title)\n",
        "    return px.bar(df.head(15), x=cols[0], y=cols[1] if len(cols)>1 else None, title=title)"
      ],
      "metadata": {
        "id": "pxbJ0rCMK8ex"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chat_history = []\n",
        "last_df = None\n",
        "last_date_col = None\n",
        "last_num_col = None\n",
        "\n",
        "def respond(message, history):\n",
        "    global last_df, last_date_col, last_num_col, llm_chat_history\n",
        "    history = history or []\n",
        "    history = history + [[message, \"ü§î Generating SQL...\"]]\n",
        "\n",
        "    try:\n",
        "        q_emb = np.array([co.embed(model=\"embed-v4.0\", texts=[message], input_type=\"search_query\", embedding_types=[\"float\"]).embeddings.float[0]]).astype('float32')\n",
        "        _, I = index.search(q_emb, k=6)\n",
        "        schema_context = \"\\n---\\n\".join([documents[i] for i in I[0]])\n",
        "\n",
        "        sql = generate_sql(message, schema_context, llm_chat_history)\n",
        "        df = run_query(sql)\n",
        "        last_df = df.copy()\n",
        "\n",
        "        explanation, _ = explain_results(df, message, sql)\n",
        "        fig = generate_plot(df, message)\n",
        "\n",
        "        date_cols = [c for c in df.columns if any(k in c.lower() for k in ['date','month','year','time'])]\n",
        "        if date_cols and len(df.select_dtypes(include='number').columns) > 0:\n",
        "            last_date_col = date_cols[0]\n",
        "            last_num_col = df.select_dtypes(include='number').columns[0]\n",
        "\n",
        "        llm_chat_history.append({\"query\": message, \"sql\": sql})\n",
        "\n",
        "        bot_response = \"**Generated SQL:**\\n```sql\\n\" + sql + \"\\n```\\n\\n\" + explanation\n",
        "        history[-1][1] = bot_response\n",
        "        return history, fig\n",
        "\n",
        "    except Exception as e:\n",
        "        friendly = \"Sorry, this query is not related to this Database.\\n\\nTry asking about:\\n‚Ä¢ Total revenue\\n‚Ä¢ Customer locations by state\\n‚Ä¢ Monthly order trends\\n‚Ä¢ Top products\\n‚Ä¢ Delivery time\"\n",
        "        history[-1][1] = friendly\n",
        "        return history, None\n",
        "\n",
        "\n",
        "def run_prophet_forecast():\n",
        "    global last_df, last_date_col, last_num_col\n",
        "    if last_df is None or last_date_col is None:\n",
        "        return \"Ask a time-series question first\", None\n",
        "    df_p = last_df[[last_date_col, last_num_col]].copy()\n",
        "    df_p.columns = ['ds', 'y']\n",
        "    df_p['ds'] = pd.to_datetime(df_p['ds'])\n",
        "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False)\n",
        "    m.fit(df_p)\n",
        "    future = m.make_future_dataframe(periods=180)\n",
        "    forecast = m.predict(future)\n",
        "    fig = plot_plotly(m, forecast)\n",
        "    fig.update_layout(title=\"üîÆ Prophet 6-Month Forecast\", height=680, template=\"plotly_white\")\n",
        "    return \"‚úÖ Prophet forecast generated!\", fig\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"Olist Data Dictionary Agent\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ü§ñ Olist Data Dictionary Agent\\n**Ask any business question ‚Üí Safe SQL ‚Üí Clean Charts**\")\n",
        "\n",
        "    chatbot = gr.Chatbot(height=620, show_label=False)\n",
        "    msg = gr.Textbox(placeholder=\"Ask any business question...\", label=\"Your Question\")\n",
        "\n",
        "    with gr.Row():\n",
        "        send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
        "        forecast_btn = gr.Button(\"üîÆ Prophet Forecast\", variant=\"stop\")\n",
        "        clear_btn = gr.Button(\"Clear Chat\", variant=\"secondary\")\n",
        "\n",
        "    plot_output = gr.Plot(label=\"üìä Visualization\")\n",
        "\n",
        "    gr.Markdown(\"### Quick Questions\")\n",
        "    with gr.Row():\n",
        "        for q in [\"Where are our customers located?\", \"What is our total revenue?\", \"Show monthly order trends\", \"Top 10 best-selling products?\", \"Average delivery time by state?\"]:\n",
        "            gr.Button(q, size=\"sm\").click(fn=lambda x=q: x, outputs=msg)\n",
        "\n",
        "    send_btn.click(respond, [msg, chatbot], [chatbot, plot_output])\n",
        "    msg.submit(respond, [msg, chatbot], [chatbot, plot_output])\n",
        "    forecast_btn.click(run_prophet_forecast, outputs=[chatbot, plot_output])\n",
        "    clear_btn.click(lambda: ([], None), outputs=[chatbot, plot_output])\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "mbOQIEC7K_2R",
        "outputId": "26801016-01ba-43cf-cf0a-c558d6bfb941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2ffd40c01c52125656.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2ffd40c01c52125656.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}